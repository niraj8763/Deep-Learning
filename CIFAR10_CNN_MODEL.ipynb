{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "CIFAR10_CNN_MODEL.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyNtROjzDHPRVOXop7NZZ2bg",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/niraj8763/Deep-Learning/blob/master/CIFAR10_CNN_MODEL.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hgLAC_klJY0e",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# required packeges\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import datasets, layers, models, regularizers, optimizers\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "import numpy as np"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pnrBXRdXJuI9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "EPOCHS = 50\n",
        "NUM_CLASSES = 10\n",
        "BATCH_SIZE = 128"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "orbqSLVFJ5Qk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def load_data():\n",
        "  (X_train,y_train),(X_test, y_test) = datasets.cifar10.load_data()\n",
        "  X_train = X_train.astype('float32')\n",
        "  X_test = X_test.astype('float32')\n",
        "  # normalize\n",
        "  mean = np.mean(X_train,axis=(0,1,2,3))\n",
        "  std = np.std(X_train,axis=(0,1,2,3))\n",
        "  X_train = (X_train-mean)/(std+1e-7)\n",
        "  X_test = (X_test-mean)/(std+1e-7)\n",
        "  # OHE\n",
        "  y_train = tf.keras.utils.to_categorical(y_train,NUM_CLASSES)\n",
        "  y_test = tf.keras.utils.to_categorical(y_test,NUM_CLASSES)\n",
        "  \n",
        "  return X_train, y_train,X_test,y_test"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yNBc_t0GLfO7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def build_model():\n",
        "  model = models.Sequential()\n",
        "  # 1st block\n",
        "  model.add(layers.Conv2D(32,(3,3),padding='same',input_shape= X_train.shape[1:],activation='relu'))\n",
        "  model.add(layers.BatchNormalization())\n",
        "  model.add(layers.Conv2D(32, (3,3), padding='same', activation='relu'))\n",
        "  model.add(layers.BatchNormalization())\n",
        "  model.add(layers.MaxPooling2D(pool_size=(2,2)))\n",
        "  model.add(layers.Dropout(0.2))\n",
        "\n",
        "  # 2nd block\n",
        "  model.add(layers.Conv2D(64, (3,3), padding='same', activation='relu'))\n",
        "  model.add(layers.BatchNormalization())\n",
        "  model.add(layers.Conv2D(64, (3,3), padding='same', activation='relu'))\n",
        "  model.add(layers.BatchNormalization())\n",
        "  model.add(layers.MaxPooling2D(pool_size=(2,2)))\n",
        "  model.add(layers.Dropout(0.4))\n",
        "\n",
        "  # 3rd block\n",
        "  model.add(layers.Conv2D(128, (3,3), padding='same', activation='relu'))\n",
        "  model.add(layers.BatchNormalization())\n",
        "  model.add(layers.Conv2D(128, (3,3), padding='same', activation='relu'))\n",
        "  model.add(layers.BatchNormalization())\n",
        "  model.add(layers.MaxPooling2D(pool_size=(2,2)))\n",
        "  model.add(layers.Dropout(0.4))\n",
        "  #Dense\n",
        "  model.add(layers.Flatten())\n",
        "  model.add(layers.Dense(NUM_CLASSES,activation='softmax'))\n",
        "  return model\n",
        "  model.summary()\n",
        "  \n"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p7Qq5ruAQfGT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "(X_train,y_train,X_test,y_test) = load_data()\n",
        "model = build_model()"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rPMvGxb-Q7SC",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 934
        },
        "outputId": "d24b055c-6155-46f7-8322-aa184eed73b0"
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d (Conv2D)              (None, 32, 32, 32)        896       \n",
            "_________________________________________________________________\n",
            "batch_normalization (BatchNo (None, 32, 32, 32)        128       \n",
            "_________________________________________________________________\n",
            "conv2d_1 (Conv2D)            (None, 32, 32, 32)        9248      \n",
            "_________________________________________________________________\n",
            "batch_normalization_1 (Batch (None, 32, 32, 32)        128       \n",
            "_________________________________________________________________\n",
            "max_pooling2d (MaxPooling2D) (None, 16, 16, 32)        0         \n",
            "_________________________________________________________________\n",
            "dropout (Dropout)            (None, 16, 16, 32)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_2 (Conv2D)            (None, 16, 16, 64)        18496     \n",
            "_________________________________________________________________\n",
            "batch_normalization_2 (Batch (None, 16, 16, 64)        256       \n",
            "_________________________________________________________________\n",
            "conv2d_3 (Conv2D)            (None, 16, 16, 64)        36928     \n",
            "_________________________________________________________________\n",
            "batch_normalization_3 (Batch (None, 16, 16, 64)        256       \n",
            "_________________________________________________________________\n",
            "max_pooling2d_1 (MaxPooling2 (None, 8, 8, 64)          0         \n",
            "_________________________________________________________________\n",
            "dropout_1 (Dropout)          (None, 8, 8, 64)          0         \n",
            "_________________________________________________________________\n",
            "conv2d_4 (Conv2D)            (None, 8, 8, 128)         73856     \n",
            "_________________________________________________________________\n",
            "batch_normalization_4 (Batch (None, 8, 8, 128)         512       \n",
            "_________________________________________________________________\n",
            "conv2d_5 (Conv2D)            (None, 8, 8, 128)         147584    \n",
            "_________________________________________________________________\n",
            "batch_normalization_5 (Batch (None, 8, 8, 128)         512       \n",
            "_________________________________________________________________\n",
            "max_pooling2d_2 (MaxPooling2 (None, 4, 4, 128)         0         \n",
            "_________________________________________________________________\n",
            "dropout_2 (Dropout)          (None, 4, 4, 128)         0         \n",
            "_________________________________________________________________\n",
            "flatten (Flatten)            (None, 2048)              0         \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 10)                20490     \n",
            "=================================================================\n",
            "Total params: 309,290\n",
            "Trainable params: 308,394\n",
            "Non-trainable params: 896\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2viwPjKRRRAM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.compile(loss='categorical_crossentropy', \n",
        "            optimizer='RMSprop', \n",
        "            metrics=['accuracy'])"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WQvKQAGiM6Ia",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "6c1472a6-6c9b-4e56-da2b-3818f2548c55"
      },
      "source": [
        "# train\n",
        "batch_size = 64\n",
        "model.fit(X_train,y_train,batch_size=batch_size,epochs=EPOCHS,validation_data=(X_test,y_test))"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/50\n",
            "782/782 [==============================] - 7s 9ms/step - loss: 1.7473 - accuracy: 0.4729 - val_loss: 1.3089 - val_accuracy: 0.5656\n",
            "Epoch 2/50\n",
            "782/782 [==============================] - 7s 8ms/step - loss: 1.1019 - accuracy: 0.6383 - val_loss: 1.0883 - val_accuracy: 0.6419\n",
            "Epoch 3/50\n",
            "782/782 [==============================] - 7s 8ms/step - loss: 0.8908 - accuracy: 0.6996 - val_loss: 0.8136 - val_accuracy: 0.7152\n",
            "Epoch 4/50\n",
            "782/782 [==============================] - 7s 8ms/step - loss: 0.7646 - accuracy: 0.7373 - val_loss: 0.7959 - val_accuracy: 0.7428\n",
            "Epoch 5/50\n",
            "782/782 [==============================] - 7s 8ms/step - loss: 0.6844 - accuracy: 0.7650 - val_loss: 0.7212 - val_accuracy: 0.7614\n",
            "Epoch 6/50\n",
            "782/782 [==============================] - 7s 9ms/step - loss: 0.6211 - accuracy: 0.7860 - val_loss: 0.6972 - val_accuracy: 0.7578\n",
            "Epoch 7/50\n",
            "782/782 [==============================] - 7s 9ms/step - loss: 0.5767 - accuracy: 0.8002 - val_loss: 0.5474 - val_accuracy: 0.8173\n",
            "Epoch 8/50\n",
            "782/782 [==============================] - 7s 8ms/step - loss: 0.5408 - accuracy: 0.8140 - val_loss: 0.5794 - val_accuracy: 0.8003\n",
            "Epoch 9/50\n",
            "782/782 [==============================] - 7s 8ms/step - loss: 0.5085 - accuracy: 0.8228 - val_loss: 0.6153 - val_accuracy: 0.7928\n",
            "Epoch 10/50\n",
            "782/782 [==============================] - 7s 8ms/step - loss: 0.4813 - accuracy: 0.8316 - val_loss: 0.6221 - val_accuracy: 0.7976\n",
            "Epoch 11/50\n",
            "782/782 [==============================] - 7s 8ms/step - loss: 0.4623 - accuracy: 0.8404 - val_loss: 0.5169 - val_accuracy: 0.8253\n",
            "Epoch 12/50\n",
            "782/782 [==============================] - 7s 8ms/step - loss: 0.4354 - accuracy: 0.8476 - val_loss: 0.5094 - val_accuracy: 0.8290\n",
            "Epoch 13/50\n",
            "782/782 [==============================] - 7s 8ms/step - loss: 0.4185 - accuracy: 0.8540 - val_loss: 0.5105 - val_accuracy: 0.8334\n",
            "Epoch 14/50\n",
            "782/782 [==============================] - 7s 8ms/step - loss: 0.4018 - accuracy: 0.8599 - val_loss: 0.4778 - val_accuracy: 0.8452\n",
            "Epoch 15/50\n",
            "782/782 [==============================] - 7s 8ms/step - loss: 0.3874 - accuracy: 0.8642 - val_loss: 0.5114 - val_accuracy: 0.8357\n",
            "Epoch 16/50\n",
            "782/782 [==============================] - 7s 8ms/step - loss: 0.3704 - accuracy: 0.8687 - val_loss: 0.4864 - val_accuracy: 0.8422\n",
            "Epoch 17/50\n",
            "782/782 [==============================] - 7s 8ms/step - loss: 0.3594 - accuracy: 0.8735 - val_loss: 0.4725 - val_accuracy: 0.8448\n",
            "Epoch 18/50\n",
            "782/782 [==============================] - 7s 8ms/step - loss: 0.3453 - accuracy: 0.8779 - val_loss: 0.4979 - val_accuracy: 0.8426\n",
            "Epoch 19/50\n",
            "782/782 [==============================] - 7s 8ms/step - loss: 0.3380 - accuracy: 0.8801 - val_loss: 0.4619 - val_accuracy: 0.8460\n",
            "Epoch 20/50\n",
            "782/782 [==============================] - 6s 8ms/step - loss: 0.3260 - accuracy: 0.8851 - val_loss: 0.4817 - val_accuracy: 0.8443\n",
            "Epoch 21/50\n",
            "782/782 [==============================] - 7s 8ms/step - loss: 0.3107 - accuracy: 0.8891 - val_loss: 0.4998 - val_accuracy: 0.8377\n",
            "Epoch 22/50\n",
            "782/782 [==============================] - 7s 8ms/step - loss: 0.3104 - accuracy: 0.8901 - val_loss: 0.4746 - val_accuracy: 0.8502\n",
            "Epoch 23/50\n",
            "782/782 [==============================] - 7s 8ms/step - loss: 0.2988 - accuracy: 0.8936 - val_loss: 0.4763 - val_accuracy: 0.8489\n",
            "Epoch 24/50\n",
            "782/782 [==============================] - 7s 8ms/step - loss: 0.2951 - accuracy: 0.8945 - val_loss: 0.4655 - val_accuracy: 0.8524\n",
            "Epoch 25/50\n",
            "782/782 [==============================] - 7s 8ms/step - loss: 0.2910 - accuracy: 0.8946 - val_loss: 0.4672 - val_accuracy: 0.8515\n",
            "Epoch 26/50\n",
            "782/782 [==============================] - 7s 8ms/step - loss: 0.2836 - accuracy: 0.8988 - val_loss: 0.4809 - val_accuracy: 0.8489\n",
            "Epoch 27/50\n",
            "782/782 [==============================] - 7s 8ms/step - loss: 0.2717 - accuracy: 0.9043 - val_loss: 0.5251 - val_accuracy: 0.8400\n",
            "Epoch 28/50\n",
            "782/782 [==============================] - 7s 8ms/step - loss: 0.2661 - accuracy: 0.9040 - val_loss: 0.4841 - val_accuracy: 0.8495\n",
            "Epoch 29/50\n",
            "782/782 [==============================] - 7s 8ms/step - loss: 0.2654 - accuracy: 0.9056 - val_loss: 0.4575 - val_accuracy: 0.8531\n",
            "Epoch 30/50\n",
            "782/782 [==============================] - 7s 8ms/step - loss: 0.2556 - accuracy: 0.9088 - val_loss: 0.4801 - val_accuracy: 0.8516\n",
            "Epoch 31/50\n",
            "782/782 [==============================] - 7s 8ms/step - loss: 0.2529 - accuracy: 0.9098 - val_loss: 0.4570 - val_accuracy: 0.8556\n",
            "Epoch 32/50\n",
            "782/782 [==============================] - 7s 8ms/step - loss: 0.2476 - accuracy: 0.9108 - val_loss: 0.4685 - val_accuracy: 0.8549\n",
            "Epoch 33/50\n",
            "782/782 [==============================] - 7s 8ms/step - loss: 0.2452 - accuracy: 0.9123 - val_loss: 0.4330 - val_accuracy: 0.8634\n",
            "Epoch 34/50\n",
            "782/782 [==============================] - 7s 8ms/step - loss: 0.2379 - accuracy: 0.9151 - val_loss: 0.4490 - val_accuracy: 0.8585\n",
            "Epoch 35/50\n",
            "782/782 [==============================] - 7s 8ms/step - loss: 0.2317 - accuracy: 0.9181 - val_loss: 0.4475 - val_accuracy: 0.8587\n",
            "Epoch 36/50\n",
            "782/782 [==============================] - 7s 8ms/step - loss: 0.2327 - accuracy: 0.9180 - val_loss: 0.4897 - val_accuracy: 0.8543\n",
            "Epoch 37/50\n",
            "782/782 [==============================] - 7s 8ms/step - loss: 0.2296 - accuracy: 0.9183 - val_loss: 0.4356 - val_accuracy: 0.8634\n",
            "Epoch 38/50\n",
            "782/782 [==============================] - 7s 8ms/step - loss: 0.2251 - accuracy: 0.9200 - val_loss: 0.4586 - val_accuracy: 0.8605\n",
            "Epoch 39/50\n",
            "782/782 [==============================] - 7s 8ms/step - loss: 0.2230 - accuracy: 0.9211 - val_loss: 0.4764 - val_accuracy: 0.8521\n",
            "Epoch 40/50\n",
            "782/782 [==============================] - 7s 8ms/step - loss: 0.2190 - accuracy: 0.9220 - val_loss: 0.4767 - val_accuracy: 0.8529\n",
            "Epoch 41/50\n",
            "782/782 [==============================] - 7s 8ms/step - loss: 0.2134 - accuracy: 0.9239 - val_loss: 0.4663 - val_accuracy: 0.8554\n",
            "Epoch 42/50\n",
            "782/782 [==============================] - 7s 8ms/step - loss: 0.2162 - accuracy: 0.9232 - val_loss: 0.4904 - val_accuracy: 0.8517\n",
            "Epoch 43/50\n",
            "782/782 [==============================] - 7s 8ms/step - loss: 0.2094 - accuracy: 0.9256 - val_loss: 0.4769 - val_accuracy: 0.8577\n",
            "Epoch 44/50\n",
            "782/782 [==============================] - 6s 8ms/step - loss: 0.2059 - accuracy: 0.9266 - val_loss: 0.4419 - val_accuracy: 0.8656\n",
            "Epoch 45/50\n",
            "782/782 [==============================] - 7s 8ms/step - loss: 0.2018 - accuracy: 0.9279 - val_loss: 0.5026 - val_accuracy: 0.8525\n",
            "Epoch 46/50\n",
            "782/782 [==============================] - 6s 8ms/step - loss: 0.2008 - accuracy: 0.9275 - val_loss: 0.4721 - val_accuracy: 0.8627\n",
            "Epoch 47/50\n",
            "782/782 [==============================] - 7s 8ms/step - loss: 0.1969 - accuracy: 0.9288 - val_loss: 0.4846 - val_accuracy: 0.8610\n",
            "Epoch 48/50\n",
            "782/782 [==============================] - 7s 8ms/step - loss: 0.1928 - accuracy: 0.9318 - val_loss: 0.4864 - val_accuracy: 0.8589\n",
            "Epoch 49/50\n",
            "782/782 [==============================] - 7s 8ms/step - loss: 0.1953 - accuracy: 0.9295 - val_loss: 0.4699 - val_accuracy: 0.8647\n",
            "Epoch 50/50\n",
            "782/782 [==============================] - 7s 8ms/step - loss: 0.1922 - accuracy: 0.9310 - val_loss: 0.4704 - val_accuracy: 0.8653\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7efd2015b080>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-peGl8oeM0Cq",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "outputId": "829c30e6-c5fa-492c-bcdc-13f5f74b6719"
      },
      "source": [
        "score = model.evaluate(X_test,y_test,batch_size=BATCH_SIZE)"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "79/79 [==============================] - 0s 4ms/step - loss: 0.4704 - accuracy: 0.8653\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZvJkh2YST3AO",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 75
        },
        "outputId": "964452e7-3961-4cf1-fafd-a7874405a1a6"
      },
      "source": [
        "print(\"\\nTest score:\", score[0])\n",
        "print('Test accuracy:', score[1])"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Test score: 0.47037172317504883\n",
            "Test accuracy: 0.8652999997138977\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}